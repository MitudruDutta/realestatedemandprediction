{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 111876,
     "databundleVersionId": 13320609,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## 1. Imports & Setup",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os, gc, warnings, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB = True\n",
    "except:\n",
    "    LGB = False\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB = True\n",
    "except:\n",
    "    XGB = False\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "INPUT_DIR = \"data\"\n",
    "OUT_DIR = \"outputs/v5\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def save(df, name):\n",
    "    path = os.path.join(OUT_DIR, name)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\"💾 Saved:\", path)\n",
    "    return path\n",
    "\n",
    "def two_stage_score(y_true, y_pred):\n",
    "    eps = 1e-12\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), eps)\n",
    "    frac_bad = np.mean(ape > 1.0)\n",
    "    if frac_bad > 0.3:\n",
    "        return 0.0\n",
    "    mask = (ape <= 1.0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(ape[mask])\n",
    "    return 1.0 - (mape / mask.mean())\n",
    "\n",
    "def evaluate(y_true, y_pred, name=\"eval\"):\n",
    "    s = two_stage_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{name}: score={s:.5f}, MAE={mae:.2f}\")\n",
    "    return s, mae\n",
    "\n",
    "print(\"✅ Libraries loaded successfully.\")\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:15:17.620966Z",
     "iopub.execute_input": "2025-10-05T14:15:17.621335Z",
     "iopub.status.idle": "2025-10-05T14:15:17.662079Z",
     "shell.execute_reply.started": "2025-10-05T14:15:17.621311Z",
     "shell.execute_reply": "2025-10-05T14:15:17.661055Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-06T15:39:27.989643Z",
     "start_time": "2025-10-06T15:39:21.841981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Load and clean base datasets",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 1: Load data\nfiles = {\n    \"new\":\"train/new_house_transactions.csv\",\n    \"new_near\":\"train/new_house_transactions_nearby_sectors.csv\",\n    \"pre\":\"train/pre_owned_house_transactions.csv\",\n    \"pre_near\":\"train/pre_owned_house_transactions_nearby_sectors.csv\",\n    \"land\":\"train/land_transactions.csv\",\n    \"land_near\":\"train/land_transactions_nearby_sectors.csv\",\n    \"poi\":\"train/sector_POI.csv\",\n    \"test\":\"test.csv\",\n}\ndata = {}\nfor k,v in files.items():\n    path = os.path.join(INPUT_DIR,v)\n    data[k] = pd.read_csv(path)\n    print(f\"{k}: {data[k].shape}\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:15:36.500735Z",
     "iopub.execute_input": "2025-10-05T14:15:36.501886Z",
     "iopub.status.idle": "2025-10-05T14:15:36.510509Z",
     "shell.execute_reply.started": "2025-10-05T14:15:36.501852Z",
     "shell.execute_reply": "2025-10-05T14:15:36.509261Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-06T15:39:37.113413Z",
     "start_time": "2025-10-06T15:39:37.060103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new: (5433, 11)\n",
      "new_near: (5360, 11)\n",
      "pre: (5360, 6)\n",
      "pre_near: (5427, 6)\n",
      "land: (5896, 6)\n",
      "land_near: (5025, 6)\n",
      "poi: (86, 142)\n",
      "test: (1152, 2)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Clean individual datasets",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 2: Cleaning\ndef clean_df(df):\n    df = df.drop_duplicates().reset_index(drop=True)\n    for c in df.select_dtypes(include=['object']).columns:\n        df[c] = df[c].astype(str).str.strip()\n    for c in df.select_dtypes(include=[np.number]).columns:\n        df[c] = df[c].fillna(0)\n    return df\n\nfor k in data:\n    data[k] = clean_df(data[k])\n\n# Drop high-null columns in POI\nnulls = data[\"poi\"].isna().mean()\ndrop_cols = nulls[nulls > 0.7].index\ndata[\"poi\"] = data[\"poi\"].drop(columns=drop_cols, errors=\"ignore\").fillna(0)\n\nprint(\"✅ Cleaned all datasets.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:16:04.971632Z",
     "iopub.execute_input": "2025-10-05T14:16:04.972097Z",
     "iopub.status.idle": "2025-10-05T14:16:05.068533Z",
     "shell.execute_reply.started": "2025-10-05T14:16:04.972064Z",
     "shell.execute_reply": "2025-10-05T14:16:05.067409Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Merge into modeling DataFrame",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 3: Merge datasets\nm = data[\"new\"].copy()\n\ndef merge_with_prefix(base, other, prefix):\n    if other is None:\n        return base\n    o = other.copy()\n    for c in o.columns:\n        if c not in [\"month\",\"sector\"]:\n            o.rename(columns={c: f\"{prefix}_{c}\"}, inplace=True)\n    return base.merge(o, on=[\"month\",\"sector\"], how=\"left\")\n\nm = merge_with_prefix(m, data[\"pre\"], \"pre\")\nm = merge_with_prefix(m, data[\"land\"], \"land\")\nm = merge_with_prefix(m, data[\"new_near\"], \"new_near\")\nm = merge_with_prefix(m, data[\"pre_near\"], \"pre_near\")\nm = merge_with_prefix(m, data[\"land_near\"], \"land_near\")\nm = m.merge(data[\"poi\"], on=\"sector\", how=\"left\")\n\nm = m.fillna(0)\nprint(\"✅ Merged modeling dataset:\", m.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:16:15.875962Z",
     "iopub.execute_input": "2025-10-05T14:16:15.876309Z",
     "iopub.status.idle": "2025-10-05T14:16:16.145398Z",
     "shell.execute_reply.started": "2025-10-05T14:16:15.876282Z",
     "shell.execute_reply": "2025-10-05T14:16:16.144362Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Feature Engineering (lags, ratios, logs)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 4: Feature engineering\nm = m.sort_values([\"sector\",\"month\"]).reset_index(drop=True)\n\ndef safe_div(a, b): return np.where(b!=0, a/(b+1e-6), 0)\n\n# Ratio features\nm[\"price_area_ratio\"] = safe_div(m[\"price_new_house_transactions\"], m[\"area_new_house_transactions\"])\nm[\"land_value_density\"] = safe_div(\n    m.get(\"land_transaction_amount\", m.get(\"land_transaction_amount_land\", 0)),\n    m.get(\"construction_area\", m.get(\"construction_area_land\", 0))\n)\nm[\"new_vs_pre_owned_price\"] = safe_div(\n    m[\"price_new_house_transactions\"], m.get(\"price_pre_owned_house_transactions\", 0)\n)\n\n# Lag features\nfor col in [\"amount_new_house_transactions\",\"num_new_house_transactions\",\"area_new_house_transactions\"]:\n    if col in m.columns:\n        m[f\"{col}_lag1\"] = m.groupby(\"sector\")[col].shift(1).fillna(0)\n        m[f\"{col}_roll3\"] = m.groupby(\"sector\")[col].rolling(3,1).mean().reset_index(level=0,drop=True)\n\n# Log target\nm[\"y_log1p\"] = np.log1p(m[\"amount_new_house_transactions\"].clip(lower=0))\nprint(\"✅ Feature engineering done. Shape:\", m.shape)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:16:32.215987Z",
     "iopub.execute_input": "2025-10-05T14:16:32.216405Z",
     "iopub.status.idle": "2025-10-05T14:16:32.449985Z",
     "shell.execute_reply.started": "2025-10-05T14:16:32.216381Z",
     "shell.execute_reply": "2025-10-05T14:16:32.448824Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Feature selection",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 5: Feature selection\nnum_cols = m.select_dtypes(include=[np.number]).columns\ncorr = m[num_cols].corr()[\"amount_new_house_transactions\"].abs().sort_values(ascending=False)\ntop_feats = corr.index[1:150].tolist()  # top 150\nprint(\"✅ Selected\", len(top_feats), \"features.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:16:43.855829Z",
     "iopub.execute_input": "2025-10-05T14:16:43.856192Z",
     "iopub.status.idle": "2025-10-05T14:16:45.542939Z",
     "shell.execute_reply.started": "2025-10-05T14:16:43.856158Z",
     "shell.execute_reply": "2025-10-05T14:16:45.541798Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Train ensemble (LightGBM + XGBoost)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 6: Ensemble training\nX = m[top_feats].fillna(0)\ny_log = m[\"y_log1p\"].values\ny_true = m[\"amount_new_house_transactions\"].values\n\n# Load test\ntest = data[\"test\"].copy()\nfor f in top_feats:\n    if f not in test.columns:\n        test[f] = 0\nX_test = test[top_feats].fillna(0)\n\n# LightGBM\nif LGB:\n    dtrain = lgb.Dataset(X, label=y_log)\n    lgb_params = {\n        \"objective\":\"regression\",\"metric\":\"mae\",\n        \"learning_rate\":0.02,\"num_leaves\":256,\"feature_fraction\":0.75,\n        \"bagging_fraction\":0.75,\"lambda_l1\":0.5,\"lambda_l2\":1.0,\n        \"verbosity\":-1,\"seed\":SEED\n    }\n    print(\"⚙️ Training LightGBM...\")\n    lgbm = lgb.train(lgb_params, dtrain, num_boost_round=2000)\n    p_lgb = np.expm1(lgbm.predict(X_test))\nelse:\n    p_lgb = np.zeros(len(X_test))\n\n# XGBoost\nif XGB:\n    print(\"⚙️ Training XGBoost...\")\n    dtrain_x = xgb.DMatrix(X, label=y_log)\n    xgb_params = {\n        \"objective\":\"reg:squarederror\",\"eta\":0.02,\n        \"max_depth\":8,\"subsample\":0.8,\"colsample_bytree\":0.8,\"seed\":SEED\n    }\n    xgbm = xgb.train(xgb_params, dtrain_x, num_boost_round=1500)\n    p_xgb = np.expm1(xgbm.predict(xgb.DMatrix(X_test)))\nelse:\n    p_xgb = np.zeros(len(X_test))\n\n# Blend\nfinal_pred = 0.7*p_lgb + 0.3*p_xgb\nprint(\"✅ Model training done.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:16:58.746629Z",
     "iopub.execute_input": "2025-10-05T14:16:58.747194Z",
     "iopub.status.idle": "2025-10-05T14:17:03.330197Z",
     "shell.execute_reply.started": "2025-10-05T14:16:58.747156Z",
     "shell.execute_reply": "2025-10-05T14:17:03.329253Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Build submission before fix",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 7: Pre-fix submission\nsub = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"new_house_transaction_amount\": final_pred\n})\nprint(\"✅ Raw submission built.\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:17:14.590855Z",
     "iopub.execute_input": "2025-10-05T14:17:14.591210Z",
     "iopub.status.idle": "2025-10-05T14:17:14.727419Z",
     "shell.execute_reply.started": "2025-10-05T14:17:14.591179Z",
     "shell.execute_reply": "2025-10-05T14:17:14.726126Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Smart Post-Processing & Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 8: Smart post-processing to improve leaderboard score\n\nprint(\"🔧 Starting V5 Post-Processing\")\nsub = sub.copy()\n\n# --- 1️⃣ Unit correction ---\nmean_pred = sub[\"new_house_transaction_amount\"].mean()\nif mean_pred > 1e5:\n    print(f\"⚠️ Detected unit mismatch (mean={mean_pred:.1f}), dividing by 10,000.\")\n    sub[\"new_house_transaction_amount\"] /= 10000.0\nelse:\n    print(\"✅ Units look consistent (10,000 yuan scale confirmed).\")\n\n# --- 2️⃣ Outlier clipping ---\nq_low, q_high = sub[\"new_house_transaction_amount\"].quantile([0.01, 0.99])\nsub[\"new_house_transaction_amount\"] = sub[\"new_house_transaction_amount\"].clip(q_low*0.5, q_high*1.5)\nprint(\"✅ Clipped outlier predictions.\")\n\n# --- 3️⃣ Sector fallback for zeros ---\nif \"amount_new_house_transactions\" in m.columns:\n    sector_means = m.groupby(\"sector\")[\"amount_new_house_transactions\"].mean().to_dict()\n    sub[\"sector\"] = sub[\"id\"].str.extract(r\"sector (\\d+)\")[0]\n    sub[\"sector_mean\"] = sub[\"sector\"].map(sector_means)\n    mask = (sub[\"new_house_transaction_amount\"] < 1.0) & (sub[\"sector_mean\"].notna())\n    sub.loc[mask, \"new_house_transaction_amount\"] = sub.loc[mask, \"sector_mean\"] * 0.8\n    print(f\"✅ Replaced {mask.sum()} zero predictions with sector means.\")\n\n# --- 4️⃣ Smooth per-sector over months ---\nsub[\"month\"] = sub[\"id\"].str.extract(r\"(\\d{4} \\w+)\")[0]\nsub = sub.sort_values([\"sector\",\"month\"])\nsub[\"smooth\"] = sub.groupby(\"sector\")[\"new_house_transaction_amount\"].transform(lambda s: s.rolling(3,1,center=True).mean())\nsub[\"new_house_transaction_amount\"] = np.clip(sub[\"smooth\"], 0, None)\nprint(\"✅ Smoothed predictions over months.\")\n\n# --- 5️⃣ Save submission ---\nsub = sub[[\"id\",\"new_house_transaction_amount\"]]\nsave(sub, \"submission_v5_fixed.csv\")\nprint(\"🏁 Submission ready for Kaggle upload!\")\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-05T14:20:16.113140Z",
     "iopub.execute_input": "2025-10-05T14:20:16.113489Z",
     "iopub.status.idle": "2025-10-05T14:20:44.002776Z",
     "shell.execute_reply.started": "2025-10-05T14:20:16.113469Z",
     "shell.execute_reply": "2025-10-05T14:20:44.000736Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
